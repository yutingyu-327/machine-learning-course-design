import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
import os
import numpy as np

#双卷积模块
class DoubleConv(nn.Module):
    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.double_conv = nn.Sequential(
            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),#卷积+批量归一化+ReLU激活
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True),

            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm2d(out_channels),
            nn.ReLU(inplace=True)
        )

    def forward(self, x):
        return self.double_conv(x)

#UNet结构
class UNet(nn.Module):
    def __init__(self, n_channels=3, n_classes=1):
        super(UNet, self).__init__()
        self.n_channels = n_channels#输入通道数和输出类别数
        self.n_classes = n_classes

        # 编码器
        self.inc = DoubleConv(n_channels, 64)
        self.down1 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(64, 128))
        self.down2 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(128, 256))
        self.down3 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(256, 512))
        self.down4 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(512, 1024))

        # 解码器
        self.up1 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)#反卷积
        self.up_conv1 = DoubleConv(1024, 512)
        self.up2 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)
        self.up_conv2 = DoubleConv(512, 256)
        self.up3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)
        self.up_conv3 = DoubleConv(256, 128)
        self.up4 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)
        self.up_conv4 = DoubleConv(128, 64)

        self.outc = nn.Conv2d(64, n_classes, kernel_size=1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        #编码器前向传播
        x1 = self.inc(x)
        x2 = self.down1(x1)
        x3 = self.down2(x2)
        x4 = self.down3(x3)
        x5 = self.down4(x4)

        #解码器的前向传播，使用跳跃连接
        x = self.up1(x5)
        x = self.up_conv1(torch.cat([x4, x], dim=1))
        x = self.up2(x)
        x = self.up_conv2(torch.cat([x3, x], dim=1))
        x = self.up3(x)
        x = self.up_conv3(torch.cat([x2, x], dim=1))
        x = self.up4(x)
        x = self.up_conv4(torch.cat([x1, x], dim=1))
        x = self.outc(x)
        return self.sigmoid(x)

#处理图像
class BloodVesselDataset(Dataset):
    def __init__(self, base_dir, is_train=True, transform=None, target_transform=None):
        self.base_dir = base_dir
        self.is_train = is_train
        self.transform = transform#图像变换
        self.target_transform = target_transform#标签变换

        
        if self.is_train:
            self.img_dir = os.path.join(base_dir, 'train', 'image')
            self.label_dir = os.path.join(base_dir, 'train', 'label')

        self.images = [f for f in os.listdir(self.img_dir) if f.endswith('.jpg')]

    def __len__(self):
        """
        返回数据集中的样本数量
        """
        # 根据你的数据结构返回正确的长度
        # 例如，如果你的数据集是基于文件列表的：
        return len(self.images)  # 或者 self.samples, self.data 等

    def __getitem__(self, idx):
        img_name = self.images[idx]
        img_path = os.path.join(self.img_dir, img_name)
        image = Image.open(img_path).convert('RGB')#使用PIL库打开图像，并转换为RGB格式

        if self.is_train:
            label_path = os.path.join(self.label_dir, img_name.replace('.jpg', '.gif'))#加载标签，由于文件本质是gif，改为gif格式
            label = Image.open(label_path).convert('L')#将标签转换为灰度图像

            if self.transform:#处理图像
                image = self.transform(image)
            if self.target_transform:
                label = self.target_transform(label)

            return image, label

def train():
    device = torch.device('cuda')

    base_dir = os.path.dirname(os.path.abspath(__file__))
    output_dir = os.path.join(base_dir, 'output')
    os.makedirs(output_dir, exist_ok=True)

    transform = transforms.Compose([#unet规定的图像处理
        transforms.Resize((256, 256)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                             std=[0.229, 0.224, 0.225])
    ])

    target_transform = transforms.Compose([#unet规定的标签处理
        transforms.Resize((256, 256)),
        transforms.ToTensor()
    ])

    train_dataset = BloodVesselDataset(
        base_dir=base_dir,
        is_train=True,
        transform=transform,
        target_transform=target_transform
    )

    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)#自动添加批次维度

    model = UNet(n_channels=3, n_classes=1).to(device)

    criterion = nn.BCELoss()#二元交叉熵损失
    optimizer = optim.AdamW(model.parameters(), lr=0.001)


    num_epochs = 3000
    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0

        for i, (images, labels) in enumerate(train_loader):
            images = images.to(device)
            labels = labels.to(device)

            outputs = model(images)
            loss = criterion(outputs, labels)

            optimizer.zero_grad()#清空梯度
            loss.backward()
            optimizer.step()

            running_loss += loss.item()

        print(f'第{epoch+1}轮训练完成, 总损失: {running_loss:.4f}')

    final_model_path = os.path.join(output_dir, 'final_model.pth')
    torch.save(model.state_dict(), final_model_path)
    print(f'最终模型已保存: {final_model_path}')

if __name__ == '__main__':
    train()
import torch
from torchvision import transforms
from PIL import Image
import os
from train import UNet
import cv2
import numpy as np
from PIL import Image as PILImage


def predict():
    device = torch.device('cuda')

    main_dir = os.path.dirname(os.path.abspath(__file__))
    output_dir = os.path.join(main_dir, 'output') 
    os.makedirs(output_dir, exist_ok=True)

    model = UNet(n_channels=3, n_classes=1).to(device)
    model_path = os.path.join(output_dir, 'final_model.pth')
    model.load_state_dict(torch.load(model_path))
    model.eval()#评估

    # 在你的代码第19行后添加检查
    print(f"模型文件是否存在: {os.path.exists(model_path)}")
    if os.path.exists(model_path):
        print(f"模型文件大小: {os.path.getsize(model_path)} 字节")

    transform = transforms.Compose([
        transforms.Resize((256, 256)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406],
                           std=[0.229, 0.224, 0.225])
    ])

    test_dir = os.path.join(main_dir, 'test', 'image')
    test_images = [f for f in os.listdir(test_dir) if f.endswith('.jpg')]

    with torch.no_grad():
        for img_name in test_images:
            img_path = os.path.join(test_dir, img_name)
            image = Image.open(img_path).convert('RGB')
            input_tensor = transform(image).unsqueeze(0).to(device)#添加批次维度

            output = model(input_tensor)
    
            pred = output.cpu().squeeze().numpy()#在cpu上去除添加的批次，并转换为numpy数组
            pred = (pred > 0.5).astype(np.uint8) * 255#二值化图像
            
            original_size = image.size  
            pred_resized = cv2.resize(pred, (original_size[0], original_size[1]))#将预测图片恢复到原本大小

            output_path = os.path.join(output_dir, img_name.replace('.jpg', '.png'))
            pil_image = PILImage.fromarray(pred_resized)
            pil_image.save(output_path)
            print(f"✓ 使用PIL保存成功: {output_path}")


if __name__ == '__main__':
    predict()