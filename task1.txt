import numpy as np
import cv2
import os
import pandas as pd
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier, VotingClassifier, GradientBoostingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.feature_selection import SelectKBest, f_classif
import joblib
from tqdm import tqdm
from xgboost import XGBClassifier
import warnings
warnings.filterwarnings('ignore')

class OptimizedPlantClassifier90:
    def __init__(self, img_size=(256, 256)):  # å¢å¤§å›¾åƒå°ºå¯¸è·å–æ›´å¤šç‰¹å¾
        self.img_size = img_size
        self.scaler = StandardScaler()
        self.label_encoder = LabelEncoder()
        self.model = None
        self.feature_selector = None
        
    def extract_rich_features(self, img_path):
        """ä¸°å¯Œçš„ç‰¹å¾æå– - é’ˆå¯¹æ¤ç‰©å¹¼è‹—ä¼˜åŒ–"""
        img = cv2.imread(img_path)
        if img is None:
            return None
        
        img = cv2.resize(img, self.img_size)
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        
        features = []
        
        # 1. é¢œè‰²ç‰¹å¾ï¼ˆæ¤ç‰©åˆ†ç±»çš„å…³é”®ï¼‰
        features.extend(self._extract_plant_color_features(img_rgb))
        
        # 2. çº¹ç†ç‰¹å¾
        features.extend(self._extract_plant_texture_features(img_gray))
        
        # 3. å½¢çŠ¶ç‰¹å¾
        features.extend(self._extract_plant_shape_features(img_gray))
        
        # 4. å¶è„‰ç‰¹å¾ï¼ˆé’ˆå¯¹æ¤ç‰©ï¼‰
        features.extend(self._extract_vein_features(img_gray))
        
        # 5. å±€éƒ¨ç‰¹å¾
        features.extend(self._extract_local_features(img_gray))
        
        return np.array(features)
    
    def _extract_plant_color_features(self, img_rgb):
        """æ¤ç‰©ä¸“ç”¨é¢œè‰²ç‰¹å¾"""
        features = []
        
        # 1. HSVé¢œè‰²ç©ºé—´ï¼ˆå¯¹æ¤ç‰©æœ€æœ‰æ•ˆï¼‰
        img_hsv = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2HSV)
        
        # HSVå®Œæ•´ç›´æ–¹å›¾
        for i in range(3):
            hist = cv2.calcHist([img_hsv], [i], None, [32], [0, 256])
            hist = cv2.normalize(hist, hist).flatten()
            features.extend(hist)
        
        # 2. ç»¿è‰²é€šé“ç‰¹åˆ«å…³æ³¨ï¼ˆæ¤ç‰©ç‰¹å¾ï¼‰
        green_channel = img_rgb[:, :, 1].flatten()
        green_features = [
            np.mean(green_channel),
            np.std(green_channel),
            np.median(green_channel),
            np.max(green_channel) - np.min(green_channel),
            np.percentile(green_channel, 25),
            np.percentile(green_channel, 75),
            np.sum(green_channel > 150) / len(green_channel)  # é«˜ç»¿è‰²åƒç´ æ¯”ä¾‹
        ]
        features.extend(green_features)
        
        # 3. é¢œè‰²å¤šæ ·æ€§
        img_lab = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2LAB)
        for i in range(3):
            channel = img_lab[:, :, i].flatten()
            features.append(np.std(channel))  # é¢œè‰²å˜åŒ–
        
        # 4. é¢œè‰²çŸ©ï¼ˆé¢œè‰²åˆ†å¸ƒï¼‰
        for i in range(3):
            hist = cv2.calcHist([img_rgb], [i], None, [8], [0, 256])
            hist = cv2.normalize(hist, hist).flatten()
            features.extend(hist[:3])  # å‰ä¸‰ä¸ªçŸ©
        
        return features
    
    def _extract_plant_texture_features(self, gray_img):
        """æ¤ç‰©ä¸“ç”¨çº¹ç†ç‰¹å¾"""
        features = []
        
        # 1. å¤šå°ºåº¦LBPï¼ˆå¶çº¹ç†ï¼‰
        from skimage.feature import local_binary_pattern
        
        lbp_features = []
        for radius in [1, 2, 3]:
            n_points = 8 * radius
            lbp = local_binary_pattern(gray_img, n_points, radius, method='uniform')
            
            # LBPç›´æ–¹å›¾
            n_bins = min(10, int(lbp.max() + 1))
            hist, _ = np.histogram(lbp.ravel(), bins=n_bins, range=(0, n_bins))
            hist = hist.astype("float") / (hist.sum() + 1e-6)
            lbp_features.extend(hist)
        
        features.extend(lbp_features[:20])  # å–å‰20ä¸ª
        
        # 2. ç°åº¦å…±ç”ŸçŸ©é˜µï¼ˆç®€åŒ–ç‰ˆï¼‰
        try:
            # ç¼©å°å›¾åƒåŠ é€Ÿè®¡ç®—
            small_img = cv2.resize(gray_img, (64, 64))
            small_img = (small_img / 4).astype(np.uint8)
            
            from skimage.feature import graycomatrix, graycoprops
            glcm = graycomatrix(small_img, distances=[1], angles=[0],
                               levels=64, symmetric=True, normed=True)
            
            props = ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation']
            for prop in props:
                feature = graycoprops(glcm, prop)
                features.extend(feature.flatten())
        except:
            features.extend([0] * 5)
        
        # 3. ç°åº¦ç»Ÿè®¡
        gray_flat = gray_img.flatten()
        stats = [
            np.mean(gray_flat),
            np.std(gray_flat),
            np.median(gray_flat),
            np.var(gray_flat),
            np.max(gray_flat),
            np.min(gray_flat),
            np.percentile(gray_flat, 10),
            np.percentile(gray_flat, 90),
            np.sum(gray_flat > 128) / len(gray_flat)  # äº®åƒç´ æ¯”ä¾‹
        ]
        features.extend(stats)
        
        return features
    
    def _extract_plant_shape_features(self, gray_img):
        """æ¤ç‰©ä¸“ç”¨å½¢çŠ¶ç‰¹å¾"""
        # ä½¿ç”¨è‡ªé€‚åº”é˜ˆå€¼æ›´å¥½åœ°æå–æ¤ç‰©å½¢çŠ¶
        binary = cv2.adaptiveThreshold(gray_img, 255, 
                                      cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                      cv2.THRESH_BINARY_INV, 11, 2)
        
        # å½¢æ€å­¦æ“ä½œ
        kernel = np.ones((5, 5), np.uint8)
        binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
        binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)
        
        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        if len(contours) == 0:
            return [0] * 20
        
        # å–å‰3ä¸ªæœ€å¤§è½®å»“ï¼ˆå¯èƒ½æœ‰å¤šç‰‡å¶å­ï¼‰
        contours = sorted(contours, key=cv2.contourArea, reverse=True)[:3]
        
        features = []
        
        for i, contour in enumerate(contours):
            if i >= 2:  # åªå–å‰2ä¸ª
                break
                
            # åŸºç¡€å½¢çŠ¶ç‰¹å¾
            area = cv2.contourArea(contour)
            perimeter = cv2.arcLength(contour, True)
            
            x, y, w, h = cv2.boundingRect(contour)
            aspect_ratio = float(w) / h if h != 0 else 0
            
            # å½¢çŠ¶å¤æ‚åº¦
            circularity = (4 * np.pi * area) / (perimeter ** 2) if perimeter != 0 else 0
            rect_area = w * h
            rectangularity = area / rect_area if rect_area != 0 else 0
            
            # å‡¸æ€§
            hull = cv2.convexHull(contour)
            hull_area = cv2.contourArea(hull)
            solidity = area / hull_area if hull_area != 0 else 0
            
            # ç´§å‡‘åº¦
            compactness = (perimeter ** 2) / (4 * np.pi * area) if area != 0 else 0
            
            contour_features = [
                area, perimeter, aspect_ratio, circularity, 
                rectangularity, solidity, compactness
            ]
            
            features.extend(contour_features[:5])  # æ¯ä¸ªè½®å»“å–5ä¸ªæœ€é‡è¦ç‰¹å¾
        
        # å¡«å……ç¼ºå¤±å€¼
        while len(features) < 20:
            features.append(0)
        
        return features[:20]
    
    def _extract_vein_features(self, gray_img):
        """å¶è„‰ç‰¹å¾"""
        features = []
        
        # ä½¿ç”¨æ›´æ•æ„Ÿçš„Cannyæ£€æµ‹å¶è„‰
        edges = cv2.Canny(gray_img, 30, 100)
        
        # å¶è„‰å¯†åº¦
        vein_density = np.sum(edges > 0) / edges.size
        features.append(vein_density)
        
        # å¶è„‰æ–¹å‘æ€§
        sobelx = cv2.Sobel(gray_img, cv2.CV_64F, 1, 0, ksize=3)
        sobely = cv2.Sobel(gray_img, cv2.CV_64F, 0, 1, ksize=3)
        gradient_direction = np.arctan2(sobely, sobelx) * 180 / np.pi
        
        # æ–¹å‘ç›´æ–¹å›¾
        hist, _ = np.histogram(gradient_direction.flatten(), bins=12, range=(-180, 180))
        hist = hist.astype("float") / (hist.sum() + 1e-6)
        features.extend(hist)
        
        # å¶è„‰è¿é€šæ€§
        num_labels, labels = cv2.connectedComponents(edges)
        features.append(num_labels / edges.size * 1000)  # è¿é€šåŒºåŸŸå¯†åº¦
        
        return features
    
    def _extract_local_features(self, gray_img):
        """å±€éƒ¨ç‰¹å¾"""
        features = []
        
        # å›¾åƒåˆ†å—ç»Ÿè®¡
        h, w = gray_img.shape
        block_size = 64
        
        for i in range(0, h, block_size):
            for j in range(0, w, block_size):
                if i + block_size <= h and j + block_size <= w:
                    block = gray_img[i:i+block_size, j:j+block_size]
                    if block.size > 0:
                        features.append(np.mean(block))
                        features.append(np.std(block))
        
        # å–å‰16ä¸ªå—çš„ç‰¹å¾
        return features[:16]
    
    def prepare_dataset_with_augmentation(self, data_dir, categories=None):
        """å‡†å¤‡æ•°æ®é›†å¹¶è¿›è¡Œæœ‰æ•ˆçš„æ•°æ®å¢å¼º"""
        if categories is None:
            categories = [d for d in os.listdir(data_dir) 
                         if os.path.isdir(os.path.join(data_dir, d))]
        
        X_all = []
        y_all = []
        
        print("æå–ç‰¹å¾å¹¶è¿›è¡Œåœ¨çº¿æ•°æ®å¢å¼º...")
        
        for category in tqdm(categories, desc="å¤„ç†ç±»åˆ«"):
            category_dir = os.path.join(data_dir, category)
            if not os.path.isdir(category_dir):
                continue
            
            image_files = [f for f in os.listdir(category_dir) 
                          if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
            
            original_count = len(image_files)
            target_count = max(200, original_count * 3)  # ç›®æ ‡æ¯ç±»200-600æ ·æœ¬
            
            for idx, img_file in enumerate(image_files):
                img_path = os.path.join(category_dir, img_file)
                
                # åŸå§‹å›¾åƒç‰¹å¾
                features = self.extract_rich_features(img_path)
                if features is not None:
                    X_all.append(features)
                    y_all.append(category)
                
                # æ•°æ®å¢å¼ºï¼šä¸ºå°‘æ•°å›¾åƒç”Ÿæˆå¢å¼ºç‰ˆæœ¬
                if original_count < 100 and idx < min(original_count, 50):
                    img = cv2.imread(img_path)
                    if img is not None:
                        # ç”Ÿæˆ2ä¸ªå¢å¼ºç‰ˆæœ¬
                        for aug_idx in range(2):
                            augmented_img = self._augment_image(img)
                            
                            # æå–å¢å¼ºå›¾åƒçš„ç‰¹å¾
                            temp_path = f'temp_aug_{category}_{idx}_{aug_idx}.jpg'
                            cv2.imwrite(temp_path, augmented_img)
                            aug_features = self.extract_rich_features(temp_path)
                            
                            if aug_features is not None:
                                X_all.append(aug_features)
                                y_all.append(category)
                            
                            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                            if os.path.exists(temp_path):
                                os.remove(temp_path)
            
            print(f"  ç±»åˆ« {category}: åŸå§‹ {original_count} -> å¢å¼ºå {len([x for x in y_all if x == category])}")
        
        X_all = np.array(X_all)
        y_all = np.array(y_all)
        
        print(f"\næœ€ç»ˆæ•°æ®é›†: {X_all.shape[0]} æ ·æœ¬, {X_all.shape[1]} ç‰¹å¾")
        
        return X_all, y_all
    
    def _augment_image(self, img):
        """å›¾åƒå¢å¼º"""
        augmented = img.copy()
        h, w = img.shape[:2]
        
        # éšæœºå¢å¼ºç»„åˆ
        import random
        
        # 1. éšæœºæ—‹è½¬ (-45Â°åˆ°45Â°)
        if random.random() > 0.5:
            angle = random.uniform(-45, 45)
            M = cv2.getRotationMatrix2D((w/2, h/2), angle, 1)
            augmented = cv2.warpAffine(augmented, M, (w, h))
        
        # 2. éšæœºç¼©æ”¾ (0.8åˆ°1.2å€)
        if random.random() > 0.5:
            scale = random.uniform(0.8, 1.2)
            augmented = cv2.resize(augmented, None, fx=scale, fy=scale)
            augmented = cv2.resize(augmented, (w, h))
        
        # 3. éšæœºç¿»è½¬
        if random.random() > 0.5:
            augmented = cv2.flip(augmented, 1)  # æ°´å¹³ç¿»è½¬
        
        # 4. éšæœºäº®åº¦è°ƒæ•´
        if random.random() > 0.5:
            brightness = random.uniform(0.7, 1.3)
            augmented = np.clip(augmented.astype(np.float32) * brightness, 0, 255).astype(np.uint8)
        
        # 5. éšæœºå¯¹æ¯”åº¦è°ƒæ•´
        if random.random() > 0.5:
            contrast = random.uniform(0.7, 1.3)
            augmented = np.clip(128 + contrast * (augmented.astype(np.float32) - 128), 0, 255).astype(np.uint8)
        
        # 6. éšæœºæ·»åŠ é«˜æ–¯å™ªå£°
        if random.random() > 0.3:
            noise = np.random.normal(0, random.uniform(5, 15), augmented.shape).astype(np.uint8)
            augmented = cv2.add(augmented, noise)
        
        return augmented
    
    def select_important_features(self, X, y, k=100):
        """é€‰æ‹©é‡è¦ç‰¹å¾ï¼ˆä¿ç•™è¶³å¤Ÿç‰¹å¾ï¼‰"""
        print(f"åŸå§‹ç‰¹å¾æ•°: {X.shape[1]}")
        
        # ä½¿ç”¨ANOVA F-valueè¿›è¡Œç‰¹å¾é€‰æ‹©
        selector = SelectKBest(f_classif, k=min(k, X.shape[1]))
        X_selected = selector.fit_transform(X, y)
        
        # ä¿å­˜é€‰æ‹©å™¨
        self.feature_selector = selector
        
        print(f"é€‰æ‹©åç‰¹å¾æ•°: {X_selected.shape[1]}")
        
        return X_selected
    
    def train_advanced_ensemble(self, X, y):
        """è®­ç»ƒé«˜çº§é›†æˆæ¨¡å‹"""
        # ç¼–ç æ ‡ç­¾
        y_encoded = self.label_encoder.fit_transform(y)
        
        print(f"ç±»åˆ«: {self.label_encoder.classes_}")
        print(f"å„ç±»æ ·æœ¬æ•°: {np.bincount(y_encoded)}")
        
        # æ ‡å‡†åŒ–
        X_scaled = self.scaler.fit_transform(X)
        
        # åˆ†å‰²æ•°æ®ï¼ˆä½¿ç”¨åˆ†å±‚åˆ†å‰²ï¼‰
        X_train, X_val, y_train, y_val = train_test_split(
            X_scaled, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
        )
        
        print(f"è®­ç»ƒé›†: {X_train.shape[0]}, éªŒè¯é›†: {X_val.shape[0]}")
        
        # å®šä¹‰æ›´å¤šæ ·åŒ–çš„æ¨¡å‹
        print("\nå®šä¹‰æ¨¡å‹...")
        
        models = [
            ('xgb1', XGBClassifier(
                n_estimators=500,
                max_depth=10,
                learning_rate=0.01,
                subsample=0.7,
                colsample_bytree=0.7,
                gamma=0.5,
                reg_alpha=0.5,
                reg_lambda=1,
                random_state=42,
                n_jobs=-1,
                use_label_encoder=False,
                eval_metric='mlogloss'
            )),
            ('xgb2', XGBClassifier(
                n_estimators=300,
                max_depth=8,
                learning_rate=0.05,
                subsample=0.8,
                colsample_bytree=0.8,
                gamma=1,
                reg_alpha=1,
                reg_lambda=5,
                random_state=43,
                n_jobs=-1,
                use_label_encoder=False,
                eval_metric='mlogloss'
            )),
            ('rf1', RandomForestClassifier(
                n_estimators=500,
                max_depth=25,
                min_samples_split=5,
                min_samples_leaf=2,
                max_features='sqrt',
                random_state=42,
                n_jobs=-1,
                class_weight='balanced'
            )),
            ('rf2', RandomForestClassifier(
                n_estimators=300,
                max_depth=20,
                min_samples_split=3,
                min_samples_leaf=1,
                max_features='log2',
                random_state=43,
                n_jobs=-1,
                class_weight='balanced'
            )),
            ('gb', GradientBoostingClassifier(
                n_estimators=300,
                learning_rate=0.05,
                max_depth=7,
                subsample=0.8,
                random_state=42
            )),
            ('knn', KNeighborsClassifier(
                n_neighbors=7,
                weights='distance',
                metric='minkowski',
                p=2,
                n_jobs=-1
            ))
        ]
        
        # äº¤å‰éªŒè¯è¯„ä¼°
        cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
        
        print("\näº¤å‰éªŒè¯ç»“æœ:")
        cv_results = {}
        for name, model in models:
            try:
                scores = cross_val_score(model, X_train, y_train, cv=cv, 
                                        scoring='accuracy', n_jobs=-1, error_score='raise')
                cv_results[name] = scores.mean()
                print(f"{name}: {scores.mean():.4f} (Â±{scores.std():.4f})")
            except Exception as e:
                print(f"{name}: å¤±è´¥ - {e}")
                cv_results[name] = 0
        
        # é€‰æ‹©æœ€å¥½çš„3ä¸ªæ¨¡å‹
        best_models = sorted(cv_results.items(), key=lambda x: x[1], reverse=True)[:4]
        best_model_names = [name for name, _ in best_models]
        
        print(f"\né€‰æ‹©æœ€ä½³æ¨¡å‹: {best_model_names}")
        
        # åˆ›å»ºæŠ•ç¥¨é›†æˆ
        selected_models = [(name, model) for name, model in models if name in best_model_names]
        
        self.model = VotingClassifier(
            estimators=selected_models,
            voting='soft',
            weights=[3, 2, 2, 1],  # ç»™å‰ä¸¤ä¸ªæ¨¡å‹æ›´é«˜æƒé‡
            n_jobs=-1
        )
        
        # è®­ç»ƒé›†æˆæ¨¡å‹
        print("\nè®­ç»ƒé›†æˆæ¨¡å‹...")
        self.model.fit(X_train, y_train)
        
        # è¯„ä¼°
        train_score = self.model.score(X_train, y_train)
        val_score = self.model.score(X_val, y_val)
        
        print(f"\næ¨¡å‹æ€§èƒ½:")
        print(f"è®­ç»ƒå‡†ç¡®ç‡: {train_score:.4f}")
        print(f"éªŒè¯å‡†ç¡®ç‡: {val_score:.4f}")
        
        # è¯¦ç»†é¢„æµ‹åˆ†æ
        from sklearn.metrics import classification_report, confusion_matrix
        
        y_pred = self.model.predict(X_val)
        print("\nåˆ†ç±»æŠ¥å‘Š:")
        print(classification_report(y_val, y_pred, target_names=self.label_encoder.classes_))
        
        return val_score
    
    def predict_test_set(self, test_dir):
        """é¢„æµ‹æµ‹è¯•é›†"""
        if not os.path.exists(test_dir):
            print(f"æµ‹è¯•ç›®å½•ä¸å­˜åœ¨: {test_dir}")
            return None
        
        test_features = []
        test_filenames = []
        
        test_files = [f for f in os.listdir(test_dir) 
                     if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        print(f"æ‰¾åˆ° {len(test_files)} ä¸ªæµ‹è¯•å›¾åƒ")
        
        for test_file in tqdm(test_files, desc="æå–æµ‹è¯•ç‰¹å¾"):
            test_path = os.path.join(test_dir, test_file)
            features = self.extract_rich_features(test_path)
            
            if features is not None:
                # åº”ç”¨ç‰¹å¾é€‰æ‹©
                if self.feature_selector is not None:
                    features = self.feature_selector.transform(features.reshape(1, -1)).flatten()
                
                test_features.append(features)
                test_filenames.append(test_file)
        
        if not test_features:
            print("æ²¡æœ‰æå–åˆ°æµ‹è¯•ç‰¹å¾")
            return None
        
        X_test = np.array(test_features)
        
        # æ ‡å‡†åŒ–
        X_test_scaled = self.scaler.transform(X_test)
        
        # é¢„æµ‹
        y_pred_encoded = self.model.predict(X_test_scaled)
        predictions = self.label_encoder.inverse_transform(y_pred_encoded)
        
        # åˆ›å»ºç»“æœ
        results = pd.DataFrame({
            'ID': test_filenames,
            'Category': predictions
        })
        
        return results
    
    def save_model(self, path='plant_classifier_90.pkl'):
        """ä¿å­˜æ¨¡å‹"""
        joblib.dump({
            'scaler': self.scaler,
            'label_encoder': self.label_encoder,
            'model': self.model,
            'feature_selector': self.feature_selector,
            'img_size': self.img_size
        }, path)
        print(f"æ¨¡å‹å·²ä¿å­˜åˆ° {path}")
    
    def load_model(self, path='plant_classifier_90.pkl'):
        """åŠ è½½æ¨¡å‹"""
        data = joblib.load(path)
        self.scaler = data['scaler']
        self.label_encoder = data['label_encoder']
        self.model = data['model']
        self.feature_selector = data['feature_selector']
        self.img_size = data['img_size']
        print(f"æ¨¡å‹å·²ä» {path} åŠ è½½")

def main_90_percent():
    """ä¸»å‡½æ•° - ç›®æ ‡90%+å‡†ç¡®ç‡"""
    print("=" * 60)
    print("æ¤ç‰©å¹¼è‹—åˆ†ç±» - 90%+å‡†ç¡®ç‡ç»ˆæç‰ˆ")
    print("=" * 60)
    
    # åˆå§‹åŒ–åˆ†ç±»å™¨
    classifier = OptimizedPlantClassifier90(img_size=(256, 256))
    
    # 1. å‡†å¤‡æ•°æ®ï¼ˆå¸¦å¢å¼ºï¼‰
    TRAIN_DIR = '/kaggle/input/task1-dataset/train'
    
    if not os.path.exists(TRAIN_DIR):
        print(f"è®­ç»ƒç›®å½•ä¸å­˜åœ¨: {TRAIN_DIR}")
        return
    
    print("1. æå–ç‰¹å¾å’Œæ•°æ®å¢å¼º...")
    X, y = classifier.prepare_dataset_with_augmentation(TRAIN_DIR)
    
    if len(X) == 0:
        print("æ²¡æœ‰æ‰¾åˆ°æ•°æ®ï¼")
        return
    
    # 2. ç‰¹å¾é€‰æ‹©ï¼ˆä¿ç•™è¶³å¤Ÿç‰¹å¾ï¼‰
    print("\n2. ç‰¹å¾é€‰æ‹©...")
    X_selected = classifier.select_important_features(X, y, k=100)
    
    # 3. è®­ç»ƒé«˜çº§é›†æˆæ¨¡å‹
    print("\n3. è®­ç»ƒé«˜çº§é›†æˆæ¨¡å‹...")
    accuracy = classifier.train_advanced_ensemble(X_selected, y)
    
    # 4. æµ‹è¯•é›†é¢„æµ‹
    TEST_DIR = '/kaggle/input/task1-dataset/test'
    if os.path.exists(TEST_DIR):
        print("\n4. é¢„æµ‹æµ‹è¯•é›†...")
        results = classifier.predict_test_set(TEST_DIR)
        
        if results is not None:
            results.to_csv('plant_classification_90.csv', index=False)
            print(f"æäº¤æ–‡ä»¶å·²ä¿å­˜: plant_classification_90.csv")
            print(f"é¢„æµ‹äº† {len(results)} ä¸ªæ ·æœ¬")
            
            # æ˜¾ç¤ºé¢„æµ‹åˆ†å¸ƒ
            print("\né¢„æµ‹ç±»åˆ«åˆ†å¸ƒ:")
            print(results['Category'].value_counts())
    
    # 5. ä¿å­˜æ¨¡å‹
    classifier.save_model()
    
    # 6. ç»“æœè¯„ä¼°
    print(f"\n{'='*60}")
    print("æœ€ç»ˆç»“æœ")
    print(f"{'='*60}")
    print(f"éªŒè¯å‡†ç¡®ç‡: {accuracy:.4f}")
    
    if accuracy >= 0.90:
        print("ğŸ‰ æ­å–œï¼è¾¾åˆ°90%+å‡†ç¡®ç‡ç›®æ ‡ï¼")
    elif accuracy >= 0.85:
        print("âœ… æ¥è¿‘ç›®æ ‡ï¼Œå‡†ç¡®ç‡è‰¯å¥½")
        print("å¯ä»¥å°è¯•ä»¥ä¸‹æ”¹è¿›:")
        print("1. æ”¶é›†æ›´å¤šè®­ç»ƒæ•°æ®")
        print("2. ä½¿ç”¨é¢„è®­ç»ƒçš„æ·±åº¦å­¦ä¹ ç‰¹å¾")
        print("3. è°ƒæ•´æ¨¡å‹å‚æ•°")
    else:
        print("âš ï¸  éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
    
    return accuracy

# è¿è¡Œä¸»ç¨‹åº
if __name__ == "__main__":
    accuracy = main_90_percent()
    
    # å¦‚æœå‡†ç¡®ç‡ä¸å¤Ÿï¼Œæä¾›è¿›ä¸€æ­¥å»ºè®®
    if accuracy < 0.90:
        print("\n" + "="*60)
        print("è¿›ä¸€æ­¥ä¼˜åŒ–å»ºè®®:")
        print("="*60)
        print("1. æ•°æ®å±‚é¢:")
        print("   - ç¡®ä¿æ¯ç±»è‡³å°‘æœ‰150-200ä¸ªæ ·æœ¬")
        print("   - ä½¿ç”¨æ›´å¤æ‚çš„æ•°æ®å¢å¼ºï¼ˆæ—‹è½¬ã€è£å‰ªã€é¢œè‰²å˜æ¢ï¼‰")
        print("   - äººå·¥æ£€æŸ¥å¹¶æ¸…ç†å™ªå£°æ•°æ®")
        
        print("\n2. ç‰¹å¾å±‚é¢:")
        print("   - æå–æ·±åº¦å­¦ä¹ ç‰¹å¾ï¼ˆä½¿ç”¨é¢„è®­ç»ƒCNNï¼‰")
        print("   - å°è¯•SIFTã€SURFç­‰å±€éƒ¨ç‰¹å¾")
        print("   - ä½¿ç”¨ç‰¹å¾èåˆæŠ€æœ¯")
        
        print("\n3. æ¨¡å‹å±‚é¢:")
        print("   - å°è¯•æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼ˆCNNï¼‰")
        print("   - ä½¿ç”¨æ›´å¤æ‚çš„é›†æˆæ–¹æ³•ï¼ˆå †å ã€æå‡ï¼‰")
        print("   - è¿›è¡Œæ›´ç»†è‡´çš„è¶…å‚æ•°è°ƒä¼˜")
        
        print("\n4. åå¤„ç†:")
        print("   - ä½¿ç”¨æ¨¡å‹èåˆ")
        print("   - åº”ç”¨é›†æˆå­¦ä¹ ")
        print("   - ä½¿ç”¨æµ‹è¯•æ—¶å¢å¼ºï¼ˆTTAï¼‰")